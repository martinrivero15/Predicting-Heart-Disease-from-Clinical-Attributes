# ğŸ«€ Heart Disease Risk Prediction with Machine Learning

## ğŸ¯ Project Objective

This project aims to develop a machine learning model to predict the **severity of heart disease** (multiclass classification: levels 0 to 4) using clinical features from the [UCI Heart Disease Dataset]([https://archive.ics.uci.edu/dataset/45/heart+disease](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data)). https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data


> Rather than simplifying the task into a binary classification (0 = no disease, 1 = disease), we preserve the **five risk levels** to explore the modelâ€™s ability to predict nuanced clinical stages â€” making the solution more aligned with real-world medical decision-making.

---

## ğŸ“Š 1. Exploratory Data Analysis (EDA)

Initial analysis focused on understanding variable distributions, relationships, and class balance:

- Visualized histograms and boxplots for numerical features.
- Identified categorical features (`cp`, `restecg`, `slope`, etc.).
- Discovered **class imbalance**, especially in class 4 (most severe).
- Checked for **missing data** and **outliers**.

---

## ğŸ§¹ 2. Data Cleaning & Preprocessing (Wrangling)

Key preprocessing steps included:

- âœ… Removed rows with excessive missing values (**7+ NaNs**).
- âŒ Dropped columns `ca` and `thal` due to **>50% missing data** and low clinical interpretability.
- ğŸ§© Imputed missing values:
  - `chol`, `trestbps`, `thalach`, `oldpeak`: **Median** (due to skewed distributions).
  - `fbs`, `exang`, `restecg`: **Mode** (categorical).
  - `slope`: Introduced a new category â†’ `'unknown'`.

---

## ğŸ”¡ 3. Categorical Feature Encoding

- âœ… Applied **One-Hot Encoding** to:
  - `cp`, `restecg`, `slope` (including `'unknown'`)
- âœ… Converted boolean features `fbs` and `exang` to **0/1**.
- âŒ Dropped `id` column (non-predictive identifier).

---

## ğŸ“ 4. Feature Scaling (Normalization)

To ensure fair treatment of features in distance-sensitive algorithms, we applied:

- **RobustScaler** on:
  - `age`, `trestbps`, `chol`, `thalach`, `oldpeak`
- ğŸ“Œ Reason: Robust to **outliers** and effective for **non-Gaussian** distributions.
- âœ¨ Other scalers like `StandardScaler` were considered but discarded due to lack of robustness in medical datasets.

---

## âš–ï¸ 5. Class Imbalance Handling

The target variable `num` (heart disease level) showed significant imbalance:

| Class (Risk Level) | Count |
|--------------------|-------|
| 0 (No disease)     | 410   |
| 4 (Severe disease) | 30    |

### Applied Solution:

- Used **SMOTE** (Synthetic Minority Oversampling Technique) **only on the training set**.
- Balanced the dataset to **329 samples per class** in training.
- âš ï¸ **Decision:** Kept full multiclass structure (0â€“4) to analyze model performance across different **risk levels**, rather than simplifying to binary.

---

## ğŸ¤– 6. Machine Learning Models Used

The following classification models were trained and evaluated:

| Model | Description |
|-------|-------------|
| âœ… Logistic Regression (OvR) | Baseline for multiclass classification |
| âœ… Random Forest | Robust, interpretable ensemble method |
| âœ… Support Vector Machine | Effective for nonlinear boundaries |
| âœ… K-Nearest Neighbors | Simple, distance-based baseline |
| âœ… Gradient Boosting | Boosted decision trees for performance |
| âœ… XGBoost | Highly optimized gradient boosting |

---

## ğŸ“ˆ 7. Evaluation Metrics

Model performance was evaluated using:

- âœ… **Accuracy**
- âœ… **Classification Report** (Precision, Recall, F1-score)
- âœ… **Confusion Matrix**

> Models performed best on classes 0 and 1. Predicting classes 3 and 4 remained challenging due to fewer samples and clinical overlap â€” a realistic reflection of diagnostic complexity.

---

## ğŸ“Œ 8. Key Insights

- **Random Forest** and **XGBoost** were the top performers.
- One-hot encoding and robust scaling contributed significantly to stability.
- Outliers were **retained** due to clinical importance (e.g., extremely high blood pressure).
- Multiclass setting provides richer insights than binary classification.

---

## ğŸš€ 9. Future Improvements

Suggestions for future enhancements:

- ğŸ§  **Feature Engineering**:
  - Create derived features like age groups, risk scores, etc.
- ğŸ”§ **Hyperparameter Tuning**:
  - Use `GridSearchCV` or `Optuna`.
- ğŸ“‰ **Feature Selection**:
  - Remove redundant or highly correlated features.
- ğŸ©º **Model Explainability**:
  - Use `SHAP` or `LIME` to understand model predictions.

---

## ğŸ“ Project Structure

```
ğŸ“¦ uci-heart-disease-ml/
â”œâ”€â”€ Uci-1.ipynb            # Main Jupyter Notebook
â”œâ”€â”€ Uci-1.pdf              # PDF report
â”œâ”€â”€ README.md              # Project summary (this file)
â””â”€â”€ data/
    â””â”€â”€ heart_disease_uci.csv          # Original UCI dataset
```

---

## âœ… Conclusion

This end-to-end machine learning pipeline demonstrates how to tackle a **real-world multiclass classification problem in healthcare** â€” from raw data and preprocessing to model evaluation and strategic improvements.

The project showcases the **clinical potential** of AI/ML to assess varying **levels of cardiovascular risk**, rather than simply detecting disease presence.

> ğŸ” Interested in contributing? Fork the repo, experiment with other models, or test this framework on new medical datasets.
